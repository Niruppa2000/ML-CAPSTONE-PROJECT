{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f0747fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[   0  501]\n",
      " [   0 1999]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       501\n",
      "           1       0.80      1.00      0.89      1999\n",
      "\n",
      "    accuracy                           0.80      2500\n",
      "   macro avg       0.40      0.50      0.44      2500\n",
      "weighted avg       0.64      0.80      0.71      2500\n",
      "\n",
      "Accuracy Score: 0.7996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\aiml\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import pickle\n",
    "\n",
    "# Load and preprocess the data\n",
    "dataset1 = pd.read_csv(\"Preprocessed_Loan_Default.csv\", index_col=None)\n",
    "df2 = dataset1.copy()\n",
    "df2 = pd.get_dummies(df2, drop_first=True)\n",
    "\n",
    "# Define independent and dependent variables\n",
    "indep_X = df2.drop('Loan_Status_Non-Default', axis=1)\n",
    "dep_Y = df2['Loan_Status_Non-Default']\n",
    "\n",
    "# Function to split and scale the data\n",
    "def split_scalar(indep_X, dep_Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size=0.25, random_state=0)\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    return X_train, X_test, y_train, y_test, sc  # return scaler if saving needed later\n",
    "\n",
    "# Function to evaluate model performance\n",
    "def cm_prediction(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
    "    return model\n",
    "\n",
    "# Train and evaluate Naive Bayes model\n",
    "X_train, X_test, y_train, y_test, scaler = split_scalar(indep_X, dep_Y)\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate performance\n",
    "nb_model = cm_prediction(nb_model, X_test, y_test)\n",
    "\n",
    "# Save the model and scaler using pickle\n",
    "with open('naive_bayes_model.pkl', 'wb') as f:\n",
    "    pickle.dump(nb_model, f)\n",
    "\n",
    "with open('scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e1805cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC Score: 0.5028422394830149\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict probabilities\n",
    "y_proba = nb_model.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class\n",
    "\n",
    "# Calculate AUC-ROC score\n",
    "auc_score = roc_auc_score(y_test, y_proba)\n",
    "print(\"AUC-ROC Score:\", auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83ff993b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loan Prediction: Default\n",
      "Probability of Non-Default: 0.47\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Load the trained model and scaler\n",
    "with open('naive_bayes_model.pkl', 'rb') as f:\n",
    "    nb_model = pickle.load(f)\n",
    "\n",
    "with open('scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "# Define user input data with correct feature count (14 columns)\n",
    "user_data = pd.DataFrame([[2, 3, 1, 4, 5, 6, 2, 3, 1, 1, 5, 3, 1, 1]],\n",
    "                         columns=[\n",
    "                             'Age', 'Income', 'Credit_Score', 'Debt_to_Income_Ratio',\n",
    "                             'Existing_Loan_Balance', 'Loan_Amount', 'Interest_Rate',\n",
    "                             'Loan_Duration_Months',\n",
    "                             # Include only one dummy per category (due to drop_first=True)\n",
    "                             'Gender_Male',\n",
    "                             'Employment_Status_Unemployed',\n",
    "                             'Location_Suburban',\n",
    "                             'Location_Urban',\n",
    "                             'Other_Feature_1',\n",
    "                             'Other_Feature_2'\n",
    "                         ])\n",
    "\n",
    "# Apply scaling\n",
    "user_data_scaled = scaler.transform(user_data)\n",
    "\n",
    "# Make prediction\n",
    "Loan_prediction = nb_model.predict(user_data_scaled)\n",
    "Loan_probability = nb_model.predict_proba(user_data_scaled)[0]\n",
    "\n",
    "# Output prediction\n",
    "result = 'Non-Default' if Loan_prediction[0] == 1 else 'Default'\n",
    "print(f'Loan Prediction: {result}')\n",
    "print(f'Probability of Non-Default: {Loan_probability[1]:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a30663d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
